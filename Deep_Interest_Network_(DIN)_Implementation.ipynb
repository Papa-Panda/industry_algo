{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/industry_algo/blob/main/Deep_Interest_Network_(DIN)_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://gemini.google.com/app/72f602f1dcb0baa4\n",
        "\n",
        "# 屠龙少年与龙：漫谈深度学习驱动的广告推荐技术发展周期 - 朱小强的文章 - 知乎\n",
        "# https://zhuanlan.zhihu.com/p/398041971\n",
        "# 推荐系统中的注意力机制——阿里深度兴趣网络（DIN） - 王喆的文章 - 知乎\n",
        "# https://zhuanlan.zhihu.com/p/51623339"
      ],
      "metadata": {
        "id": "NVQSI-ivK0Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "\n",
        "# --- 1. Synthetic Data Generation ---\n",
        "# This dataset simulates user interactions with items.\n",
        "# Each user has a history of clicked items, and we'll predict if they click a new candidate item.\n",
        "\n",
        "def generate_synthetic_data(num_samples=10000, num_users=1000, num_items=500, history_length=10):\n",
        "    \"\"\"\n",
        "    Generates synthetic data for a Deep Interest Network.\n",
        "\n",
        "    Args:\n",
        "        num_samples (int): Total number of data points (user-candidate pairs).\n",
        "        num_users (int): Number of unique users.\n",
        "        num_items (int): Number of unique items.\n",
        "        history_length (int): Maximum length of a user's historical clicked items.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - np.array: User IDs.\n",
        "            - np.array: Candidate Item IDs.\n",
        "            - np.array: 2D array of Historical Item IDs (padded with 0s).\n",
        "            - np.array: Labels (1 if clicked, 0 otherwise).\n",
        "            - np.array: Item feature embeddings (simulated).\n",
        "    \"\"\"\n",
        "    user_ids = np.random.randint(1, num_users + 1, num_samples) # User IDs start from 1\n",
        "    candidate_item_ids = np.random.randint(1, num_items + 1, num_samples) # Item IDs start from 1\n",
        "\n",
        "    # Simulate historical clicked items for each user\n",
        "    historical_item_ids = []\n",
        "    for _ in range(num_samples):\n",
        "        # Random number of historical items for each sample, up to history_length\n",
        "        current_history_len = np.random.randint(1, history_length + 1)\n",
        "        history = np.random.randint(1, num_items + 1, current_history_len).tolist()\n",
        "        # Pad history with 0s if less than history_length\n",
        "        history.extend([0] * (history_length - len(history)))\n",
        "        historical_item_ids.append(history)\n",
        "    historical_item_ids = np.array(historical_item_ids)\n",
        "\n",
        "    # Simulate labels (e.g., 1 if candidate item is \"similar\" to history, 0 otherwise)\n",
        "    # This is a very simple simulation of a click, based on random chance\n",
        "    labels = np.random.randint(0, 2, num_samples)\n",
        "\n",
        "    # Simulate item feature embeddings (e.g., each item has a 16-dim embedding)\n",
        "    # We will use this for the DIN's attention mechanism\n",
        "    embedding_dim = 16\n",
        "    item_features = np.random.rand(num_items + 1, embedding_dim) # +1 for 0-padding, item 0 is dummy\n",
        "\n",
        "    print(f\"Generated synthetic data: {num_samples} samples.\")\n",
        "    print(f\"  User IDs shape: {user_ids.shape}\")\n",
        "    print(f\"  Candidate Item IDs shape: {candidate_item_ids.shape}\")\n",
        "    print(f\"  Historical Item IDs shape: {historical_item_ids.shape}\")\n",
        "    print(f\"  Labels shape: {labels.shape}\")\n",
        "    print(f\"  Item Features shape: {item_features.shape}\")\n",
        "\n",
        "    return user_ids, candidate_item_ids, historical_item_ids, labels, item_features\n",
        "\n",
        "# Generate the data\n",
        "num_users = 1000\n",
        "num_items = 500\n",
        "history_length = 10 # Max length of user behavior sequence\n",
        "embedding_dim = 16 # Dimensionality of item and user embeddings\n",
        "\n",
        "user_ids_data, candidate_item_ids_data, historical_item_ids_data, labels_data, item_features_data = \\\n",
        "    generate_synthetic_data(num_samples=50000, num_users=num_users, num_items=num_items, history_length=history_length)\n",
        "\n",
        "# --- 2. DIN Model Architecture ---\n",
        "\n",
        "# Custom Attention Layer for DIN\n",
        "class Dice(layers.Layer):\n",
        "    \"\"\"\n",
        "    Data Adaptive Activation Function (DICE) for DIN.\n",
        "    It's a variant of PReLu that learns a dynamic 'p' parameter.\n",
        "    \"\"\"\n",
        "    def __init__(self, axis=-1, epsilon=1e-9, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.alphas = self.add_weight(\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zeros',\n",
        "            trainable=True,\n",
        "            name='dice_alpha'\n",
        "        )\n",
        "        self.beta = self.add_weight(\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zeros',\n",
        "            trainable=True,\n",
        "            name='dice_beta'\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Calculate mean and variance along the specified axis\n",
        "        reduc_axis = list(range(len(inputs.shape)))\n",
        "        if self.axis != -1:\n",
        "            reduc_axis.pop(self.axis)\n",
        "        mean = tf.reduce_mean(inputs, axis=reduc_axis, keepdims=True)\n",
        "        variance = tf.reduce_mean(tf.square(inputs - mean), axis=reduc_axis, keepdims=True)\n",
        "\n",
        "        # Normalize the input\n",
        "        x_normed = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
        "\n",
        "        # Calculate p (the parameter for PReLu-like activation)\n",
        "        p = tf.sigmoid(self.alphas * x_normed + self.beta)\n",
        "\n",
        "        # Apply DICE activation\n",
        "        return p * inputs + (1 - p) * self.alphas * inputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"axis\": self.axis,\n",
        "            \"epsilon\": self.epsilon,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class AttentionPoolingLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Attention pooling layer for Deep Interest Network (DIN).\n",
        "    Calculates attention scores between candidate item and historical items,\n",
        "    then weights the historical item embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim, hidden_units=[80, 40], **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_units = hidden_units\n",
        "\n",
        "        # Attention network (e.g., MLP)\n",
        "        self.dense_layers = []\n",
        "        for units in hidden_units:\n",
        "            self.dense_layers.append(layers.Dense(units, activation=None)) # No activation initially\n",
        "            self.dense_layers.append(Dice()) # Use Dice activation after each dense layer\n",
        "\n",
        "        self.output_layer = layers.Dense(1, activation=None) # Output attention score (scalar)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs: [candidate_item_embedding, historical_item_embeddings]\n",
        "        # candidate_item_embedding: (batch_size, embedding_dim)\n",
        "        # historical_item_embeddings: (batch_size, history_length, embedding_dim)\n",
        "\n",
        "        candidate_item_embedding, historical_item_embeddings = inputs\n",
        "\n",
        "        # Expand candidate_item_embedding to match history_length dimension for concatenation\n",
        "        # (batch_size, 1, embedding_dim) -> (batch_size, history_length, embedding_dim)\n",
        "        candidate_item_embedding_expanded = tf.expand_dims(candidate_item_embedding, 1)\n",
        "        candidate_item_embedding_tiled = tf.tile(candidate_item_embedding_expanded, [1, tf.shape(historical_item_embeddings)[1], 1])\n",
        "\n",
        "        # Concatenate candidate item, historical item, their product, and their difference\n",
        "        # This is a common practice in attention mechanisms for DIN\n",
        "        # (batch_size, history_length, embedding_dim * 4)\n",
        "        concatenated_features = tf.concat([\n",
        "            candidate_item_embedding_tiled,\n",
        "            historical_item_embeddings,\n",
        "            candidate_item_embedding_tiled * historical_item_embeddings,\n",
        "            candidate_item_embedding_tiled - historical_item_embeddings\n",
        "        ], axis=-1)\n",
        "\n",
        "        # Pass through attention network\n",
        "        attention_logits = concatenated_features\n",
        "        for layer in self.dense_layers:\n",
        "            attention_logits = layer(attention_logits)\n",
        "\n",
        "        attention_logits = self.output_layer(attention_logits) # (batch_size, history_length, 1)\n",
        "\n",
        "        # Apply softmax to get attention weights.\n",
        "        # Mask out padded items (where embedding is 0) to prevent them from influencing attention.\n",
        "        # For simplicity, we assume historical_item_embeddings with all zeros corresponds to padding.\n",
        "        # A more robust approach would be to pass a mask explicitly.\n",
        "        mask = tf.cast(tf.reduce_sum(tf.abs(historical_item_embeddings), axis=-1, keepdims=True) > 0, tf.float32)\n",
        "        attention_logits = attention_logits - (1.0 - mask) * 1e9 # Mask padded items with large negative value\n",
        "\n",
        "        attention_weights = tf.nn.softmax(attention_logits, axis=1) # (batch_size, history_length, 1)\n",
        "\n",
        "        # Weighted sum of historical item embeddings\n",
        "        # (batch_size, history_length, embedding_dim) * (batch_size, history_length, 1)\n",
        "        # -> (batch_size, history_length, embedding_dim) -> (batch_size, embedding_dim)\n",
        "        weighted_history_embedding = tf.reduce_sum(attention_weights * historical_item_embeddings, axis=1)\n",
        "\n",
        "        return weighted_history_embedding\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embedding_dim\": self.embedding_dim,\n",
        "            \"hidden_units\": self.hidden_units,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "def build_din_model(num_users, num_items, history_length, embedding_dim, item_features_matrix):\n",
        "    \"\"\"\n",
        "    Builds the Deep Interest Network (DIN) model.\n",
        "\n",
        "    Args:\n",
        "        num_users (int): Total number of unique users.\n",
        "        num_items (int): Total number of unique items.\n",
        "        history_length (int): Maximum length of user historical behavior sequence.\n",
        "        embedding_dim (int): Dimensionality of item and user embeddings.\n",
        "        item_features_matrix (np.array): Pre-trained or initial item feature embeddings.\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled DIN model.\n",
        "    \"\"\"\n",
        "    # Input Layers\n",
        "    user_id_input = keras.Input(shape=(1,), name='user_id_input', dtype='int32')\n",
        "    candidate_item_id_input = keras.Input(shape=(1,), name='candidate_item_id_input', dtype='int32')\n",
        "    historical_item_ids_input = keras.Input(shape=(history_length,), name='historical_item_ids_input', dtype='int32')\n",
        "\n",
        "    # Embedding Layers\n",
        "    # User embeddings: simple lookup\n",
        "    user_embedding_layer = layers.Embedding(\n",
        "        input_dim=num_users + 1, # +1 for 0-padding if user_id 0 exists\n",
        "        output_dim=embedding_dim,\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    user_embedding = user_embedding_layer(user_id_input) # (batch_size, 1, embedding_dim)\n",
        "    user_embedding = layers.Reshape((embedding_dim,))(user_embedding) # (batch_size, embedding_dim)\n",
        "\n",
        "    # Item embeddings: use pre-defined item_features_matrix (e.g., from pre-training or here simulated)\n",
        "    # Set trainable=False if these embeddings are fixed, True if they should be fine-tuned.\n",
        "    item_embedding_layer = layers.Embedding(\n",
        "        input_dim=num_items + 1, # +1 for 0-padding\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[item_features_matrix], # Initialize with the simulated item features\n",
        "        trainable=True, # Allow fine-tuning these embeddings during training\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Candidate item embedding\n",
        "    candidate_item_embedding = item_embedding_layer(candidate_item_id_input) # (batch_size, 1, embedding_dim)\n",
        "    candidate_item_embedding = layers.Reshape((embedding_dim,))(candidate_item_embedding) # (batch_size, embedding_dim)\n",
        "\n",
        "    # Historical items embeddings\n",
        "    historical_item_embeddings = item_embedding_layer(historical_item_ids_input) # (batch_size, history_length, embedding_dim)\n",
        "\n",
        "    # DIN Attention Mechanism\n",
        "    # The AttentionPoolingLayer computes a weighted sum of historical item embeddings\n",
        "    # based on their relevance to the candidate item.\n",
        "    attention_output = AttentionPoolingLayer(\n",
        "        embedding_dim=embedding_dim,\n",
        "        hidden_units=[80, 40], # Attention MLP hidden units\n",
        "        name='din_attention_pooling'\n",
        "    )([candidate_item_embedding, historical_item_embeddings])\n",
        "\n",
        "    # Concatenate all features for the final prediction layer\n",
        "    # These are: user_embedding, candidate_item_embedding, and the attention-weighted historical embedding\n",
        "    concatenated_features = layers.concatenate([\n",
        "        user_embedding,\n",
        "        candidate_item_embedding,\n",
        "        attention_output\n",
        "    ], axis=-1)\n",
        "\n",
        "    # Prediction MLP (Deep Network)\n",
        "    mlp_output = layers.Dense(128, activation='relu')(concatenated_features)\n",
        "    mlp_output = layers.Dropout(0.3)(mlp_output)\n",
        "    mlp_output = layers.Dense(64, activation='relu')(mlp_output)\n",
        "    mlp_output = layers.Dropout(0.3)(mlp_output)\n",
        "    mlp_output = layers.Dense(32, activation='relu')(mlp_output)\n",
        "\n",
        "    # Output layer (sigmoid for binary classification)\n",
        "    output = layers.Dense(1, activation='sigmoid', name='output')(mlp_output)\n",
        "\n",
        "    # Create the model\n",
        "    model = keras.Model(\n",
        "        inputs=[user_id_input, candidate_item_id_input, historical_item_ids_input],\n",
        "        outputs=output,\n",
        "        name='deep_interest_network'\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the DIN model\n",
        "din_model = build_din_model(\n",
        "    num_users=num_users,\n",
        "    num_items=num_items,\n",
        "    history_length=history_length,\n",
        "    embedding_dim=embedding_dim,\n",
        "    item_features_matrix=item_features_data\n",
        ")\n",
        "\n",
        "din_model.summary()\n",
        "\n",
        "# --- 3. Prepare Data for Training ---\n",
        "# Create a dictionary for model inputs\n",
        "model_inputs = {\n",
        "    'user_id_input': user_ids_data,\n",
        "    'candidate_item_id_input': candidate_item_ids_data,\n",
        "    'historical_item_ids_input': historical_item_ids_data\n",
        "}\n",
        "\n",
        "# --- 4. Train the Model ---\n",
        "print(\"\\n--- Training the DIN Model ---\")\n",
        "history = din_model.fit(\n",
        "    model_inputs,\n",
        "    labels_data,\n",
        "    batch_size=256,\n",
        "    epochs=5, # Using a small number of epochs for demonstration\n",
        "    validation_split=0.2, # Use 20% of data for validation\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining complete.\")\n",
        "print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"Final training AUC: {history.history['auc'][-1]:.4f}\")\n",
        "print(f\"Final validation AUC: {history.history['val_auc'][-1]:.4f}\")\n",
        "\n",
        "# --- 5. Make Predictions (Example) ---\n",
        "print(\"\\n--- Making Predictions (Example) ---\")\n",
        "\n",
        "# Select a few random samples for prediction\n",
        "num_predict_samples = 5\n",
        "random_indices = np.random.choice(len(user_ids_data), num_predict_samples, replace=False)\n",
        "\n",
        "sample_user_ids = user_ids_data[random_indices]\n",
        "sample_candidate_item_ids = candidate_item_ids_data[random_indices]\n",
        "sample_historical_item_ids = historical_item_ids_data[random_indices]\n",
        "sample_labels = labels_data[random_indices]\n",
        "\n",
        "sample_inputs = {\n",
        "    'user_id_input': sample_user_ids,\n",
        "    'candidate_item_id_input': sample_candidate_item_ids,\n",
        "    'historical_item_ids_input': sample_historical_item_ids\n",
        "}\n",
        "\n",
        "predictions = din_model.predict(sample_inputs)\n",
        "\n",
        "print(\"\\nSample Predictions:\")\n",
        "for i in range(num_predict_samples):\n",
        "    print(f\"  Sample {i+1}:\")\n",
        "    print(f\"    User ID: {sample_user_ids[i][0] if sample_user_ids[i].ndim > 0 else sample_user_ids[i]}\")\n",
        "    print(f\"    Candidate Item ID: {sample_candidate_item_ids[i][0] if sample_candidate_item_ids[i].ndim > 0 else sample_candidate_item_ids[i]}\")\n",
        "    print(f\"    Historical Item IDs: {sample_historical_item_ids[i]}\")\n",
        "    print(f\"    True Label: {sample_labels[i]}\")\n",
        "    print(f\"    Predicted Probability: {predictions[i][0]:.4f}\")\n",
        "    print(\"-\" * 30)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.18.0\n",
            "Generated synthetic data: 50000 samples.\n",
            "  User IDs shape: (50000,)\n",
            "  Candidate Item IDs shape: (50000,)\n",
            "  Historical Item IDs shape: (50000, 10)\n",
            "  Labels shape: (50000,)\n",
            "  Item Features shape: (501, 16)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"deep_interest_network\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"deep_interest_network\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ candidate_item_id_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_id_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ item_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m8,016\u001b[0m │ candidate_item_i… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ historical_item_… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ historical_item_id… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │     \u001b[38;5;34m16,016\u001b[0m │ user_id_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ item_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ din_attention_pool… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m8,721\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mAttentionPoolingL…\u001b[0m │                   │            │ item_embedding[\u001b[38;5;34m1\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ din_attention_po… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m6,272\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ candidate_item_id_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_id_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ item_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,016</span> │ candidate_item_i… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ historical_item_… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ historical_item_id… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,016</span> │ user_id_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ din_attention_pool… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionPoolingL…</span> │                   │            │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ din_attention_po… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,394\u001b[0m (192.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,394</span> (192.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,394\u001b[0m (192.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,394</span> (192.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training the DIN Model ---\n",
            "Epoch 1/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - accuracy: 0.5030 - auc: 0.5048 - loss: 0.6949 - val_accuracy: 0.5039 - val_auc: 0.5019 - val_loss: 0.6931\n",
            "Epoch 2/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.5007 - auc: 0.4985 - loss: 0.6935 - val_accuracy: 0.4991 - val_auc: 0.5024 - val_loss: 0.6934\n",
            "Epoch 3/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.4997 - auc: 0.4982 - loss: 0.6934 - val_accuracy: 0.4978 - val_auc: 0.4962 - val_loss: 0.6933\n",
            "Epoch 4/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.5053 - auc: 0.5100 - loss: 0.6931 - val_accuracy: 0.4974 - val_auc: 0.4996 - val_loss: 0.6940\n",
            "Epoch 5/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.5233 - auc: 0.5308 - loss: 0.6917 - val_accuracy: 0.4938 - val_auc: 0.4925 - val_loss: 0.6955\n",
            "\n",
            "Training complete.\n",
            "Final training accuracy: 0.5283\n",
            "Final validation accuracy: 0.4938\n",
            "Final training AUC: 0.5369\n",
            "Final validation AUC: 0.4925\n",
            "\n",
            "--- Making Predictions (Example) ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\n",
            "Sample Predictions:\n",
            "  Sample 1:\n",
            "    User ID: 778\n",
            "    Candidate Item ID: 453\n",
            "    Historical Item IDs: [295  11 267 497 253 208 345 223   0   0]\n",
            "    True Label: 0\n",
            "    Predicted Probability: 0.4608\n",
            "------------------------------\n",
            "  Sample 2:\n",
            "    User ID: 86\n",
            "    Candidate Item ID: 479\n",
            "    Historical Item IDs: [327 330 220   0   0   0   0   0   0   0]\n",
            "    True Label: 0\n",
            "    Predicted Probability: 0.4914\n",
            "------------------------------\n",
            "  Sample 3:\n",
            "    User ID: 579\n",
            "    Candidate Item ID: 88\n",
            "    Historical Item IDs: [372 319 129 166 266  69 394 113 258  87]\n",
            "    True Label: 1\n",
            "    Predicted Probability: 0.4791\n",
            "------------------------------\n",
            "  Sample 4:\n",
            "    User ID: 915\n",
            "    Candidate Item ID: 448\n",
            "    Historical Item IDs: [310   0   0   0   0   0   0   0   0   0]\n",
            "    True Label: 1\n",
            "    Predicted Probability: 0.4525\n",
            "------------------------------\n",
            "  Sample 5:\n",
            "    User ID: 469\n",
            "    Candidate Item ID: 488\n",
            "    Historical Item IDs: [435 160 270   0   0   0   0   0   0   0]\n",
            "    True Label: 1\n",
            "    Predicted Probability: 0.5166\n",
            "------------------------------\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vbMAHU8HKzsw",
        "outputId": "89755767-c45c-4941-cf14-d5aac99dd683"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 1. Synthetic Data Generation ---\n",
        "# This dataset simulates user interactions with items, adapted for PyTorch.\n",
        "\n",
        "def generate_synthetic_data(num_samples=10000, num_users=1000, num_items=500, history_length=10, embedding_dim=16):\n",
        "    \"\"\"\n",
        "    Generates synthetic data for a Deep Interest Network.\n",
        "\n",
        "    Args:\n",
        "        num_samples (int): Total number of data points (user-candidate pairs).\n",
        "        num_users (int): Number of unique users.\n",
        "        num_items (int): Number of unique items.\n",
        "        history_length (int): Maximum length of a user's historical clicked items.\n",
        "        embedding_dim (int): Dimensionality of item and user embeddings.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing PyTorch Tensors:\n",
        "            - user_ids (torch.Tensor): User IDs.\n",
        "            - candidate_item_ids (torch.Tensor): Candidate Item IDs.\n",
        "            - historical_item_ids (torch.Tensor): 2D array of Historical Item IDs (padded with 0s).\n",
        "            - labels (torch.Tensor): Labels (1 if clicked, 0 otherwise).\n",
        "            - item_features_matrix (np.array): Item feature embeddings (simulated, numpy for embedding init).\n",
        "    \"\"\"\n",
        "    user_ids = np.random.randint(1, num_users + 1, num_samples) # User IDs start from 1\n",
        "    candidate_item_ids = np.random.randint(1, num_items + 1, num_samples) # Item IDs start from 1\n",
        "\n",
        "    historical_item_ids = []\n",
        "    for _ in range(num_samples):\n",
        "        current_history_len = np.random.randint(1, history_length + 1)\n",
        "        history = np.random.randint(1, num_items + 1, current_history_len).tolist()\n",
        "        history.extend([0] * (history_length - len(history))) # Pad with 0s\n",
        "        historical_item_ids.append(history)\n",
        "    historical_item_ids = np.array(historical_item_ids)\n",
        "\n",
        "    labels = np.random.randint(0, 2, num_samples)\n",
        "\n",
        "    item_features_matrix = np.random.rand(num_items + 1, embedding_dim).astype(np.float32) # +1 for 0-padding, item 0 is dummy\n",
        "\n",
        "    print(f\"Generated synthetic data: {num_samples} samples.\")\n",
        "    print(f\"  User IDs shape: {user_ids.shape}\")\n",
        "    print(f\"  Candidate Item IDs shape: {candidate_item_ids.shape}\")\n",
        "    print(f\"  Historical Item IDs shape: {historical_item_ids.shape}\")\n",
        "    print(f\"  Labels shape: {labels.shape}\")\n",
        "    print(f\"  Item Features matrix shape: {item_features_matrix.shape}\")\n",
        "\n",
        "    # Convert to PyTorch Tensors\n",
        "    user_ids_t = torch.LongTensor(user_ids)\n",
        "    candidate_item_ids_t = torch.LongTensor(candidate_item_ids)\n",
        "    historical_item_ids_t = torch.LongTensor(historical_item_ids)\n",
        "    labels_t = torch.FloatTensor(labels).unsqueeze(1) # Add a dimension for BCEWithLogitsLoss\n",
        "\n",
        "    return user_ids_t, candidate_item_ids_t, historical_item_ids_t, labels_t, item_features_matrix\n",
        "\n",
        "# Generate the data\n",
        "num_users = 1000\n",
        "num_items = 500\n",
        "history_length = 10 # Max length of user behavior sequence\n",
        "embedding_dim = 16 # Dimensionality of item and user embeddings\n",
        "\n",
        "user_ids_data, candidate_item_ids_data, historical_item_ids_data, labels_data, item_features_data_np = \\\n",
        "    generate_synthetic_data(num_samples=50000, num_users=num_users, num_items=num_items, history_length=history_length, embedding_dim=embedding_dim)\n",
        "\n",
        "# --- 2. DIN Model Architecture in PyTorch ---\n",
        "\n",
        "# Custom Activation Function (Dice)\n",
        "class Dice(nn.Module):\n",
        "    \"\"\"\n",
        "    Data Adaptive Activation Function (DICE) for DIN in PyTorch.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, epsilon=1e-9):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        # alphas and beta are learnable parameters, one for each feature dimension\n",
        "        self.alphas = nn.Parameter(torch.zeros(input_dim))\n",
        "        self.beta = nn.Parameter(torch.zeros(input_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Calculate mean and variance along batch and sequence dimensions,\n",
        "        # keeping the feature dimension intact.\n",
        "        # Example: if x is (batch_size, seq_len, features_dim),\n",
        "        # mean and variance will be (1, 1, features_dim)\n",
        "        reduction_axes = tuple(range(x.dim() - 1))\n",
        "        mean = torch.mean(x, dim=reduction_axes, keepdim=True)\n",
        "        variance = torch.mean(torch.pow(x - mean, 2), dim=reduction_axes, keepdim=True)\n",
        "\n",
        "        x_normed = (x - mean) / torch.sqrt(variance + self.epsilon)\n",
        "\n",
        "        # p is calculated element-wise across the feature dimension\n",
        "        p = torch.sigmoid(self.alphas * x_normed + self.beta)\n",
        "\n",
        "        # Apply DICE activation formula\n",
        "        return p * x + (1 - p) * self.alphas * x\n",
        "\n",
        "# Attention Pooling Layer for DIN\n",
        "class AttentionPoolingLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention pooling layer for Deep Interest Network (DIN) in PyTorch.\n",
        "    Calculates attention scores between candidate item and historical items,\n",
        "    then weights the historical item embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim, hidden_units=[80, 40]):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_units = hidden_units\n",
        "\n",
        "        # Attention network (MLP)\n",
        "        attention_mlp_layers = []\n",
        "        input_dim_mlp = embedding_dim * 4 # Concatenated features: candidate, history, product, difference\n",
        "\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            attention_mlp_layers.append(nn.Linear(input_dim_mlp, units))\n",
        "            attention_mlp_layers.append(Dice(units)) # Apply Dice activation\n",
        "            input_dim_mlp = units # Update input_dim for the next layer\n",
        "\n",
        "        self.attention_mlp = nn.Sequential(*attention_mlp_layers)\n",
        "        self.output_layer = nn.Linear(input_dim_mlp, 1) # Outputs a single attention score\n",
        "\n",
        "    def forward(self, candidate_item_embedding, historical_item_embeddings):\n",
        "        # candidate_item_embedding: (batch_size, embedding_dim)\n",
        "        # historical_item_embeddings: (batch_size, history_length, embedding_dim)\n",
        "\n",
        "        batch_size, history_length, _ = historical_item_embeddings.shape\n",
        "\n",
        "        # Expand candidate_item_embedding to match history_length dimension for concatenation\n",
        "        # (batch_size, 1, embedding_dim) -> (batch_size, history_length, embedding_dim)\n",
        "        candidate_item_embedding_tiled = candidate_item_embedding.unsqueeze(1).expand(-1, history_length, -1)\n",
        "\n",
        "        # Concatenate candidate item, historical item, their product, and their difference\n",
        "        # Resulting shape: (batch_size, history_length, embedding_dim * 4)\n",
        "        concatenated_features = torch.cat([\n",
        "            candidate_item_embedding_tiled,\n",
        "            historical_item_embeddings,\n",
        "            candidate_item_embedding_tiled * historical_item_embeddings,\n",
        "            candidate_item_embedding_tiled - historical_item_embeddings\n",
        "        ], dim=-1)\n",
        "\n",
        "        # Pass through attention network\n",
        "        attention_logits = self.attention_mlp(concatenated_features) # (batch_size, history_length, hidden_units[-1])\n",
        "        attention_logits = self.output_layer(attention_logits) # (batch_size, history_length, 1)\n",
        "\n",
        "        # Mask out padded items (where the historical_item_embeddings are all zeros)\n",
        "        # Create a mask: sum of absolute values along embedding dim will be zero for padded items\n",
        "        mask = (historical_item_embeddings.abs().sum(dim=-1, keepdim=True) > 0).float()\n",
        "        attention_logits = attention_logits - (1.0 - mask) * 1e9 # Apply large negative value to masked logits\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = F.softmax(attention_logits, dim=1) # (batch_size, history_length, 1)\n",
        "\n",
        "        # Weighted sum of historical item embeddings\n",
        "        # (batch_size, history_length, embedding_dim) * (batch_size, history_length, 1)\n",
        "        # -> (batch_size, history_length, embedding_dim) -> sum over history_length -> (batch_size, embedding_dim)\n",
        "        weighted_history_embedding = torch.sum(attention_weights * historical_item_embeddings, dim=1)\n",
        "\n",
        "        return weighted_history_embedding\n",
        "\n",
        "# Deep Interest Network (DIN) Model\n",
        "class DIN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, history_length, embedding_dim, item_features_matrix):\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.history_length = history_length\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Embedding layers\n",
        "        self.user_embedding = nn.Embedding(num_users + 1, embedding_dim)\n",
        "        # Initialize item embedding with pre-defined matrix (e.g., from pre-training)\n",
        "        # Ensure it's a float tensor for embedding weights\n",
        "        self.item_embedding = nn.Embedding.from_pretrained(\n",
        "            torch.from_numpy(item_features_matrix).float(),\n",
        "            freeze=False # Allow fine-tuning during training\n",
        "        )\n",
        "\n",
        "        # DIN Attention Pooling Layer\n",
        "        self.attention_pooling_layer = AttentionPoolingLayer(embedding_dim=embedding_dim)\n",
        "\n",
        "        # Final Prediction MLP\n",
        "        # Input dim for MLP: user_embedding (embedding_dim) + candidate_item_embedding (embedding_dim)\n",
        "        #                     + attention_output (embedding_dim)\n",
        "        input_mlp_dim = embedding_dim * 3\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_mlp_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # Output layer with sigmoid for binary classification probability\n",
        "        self.output_layer = nn.Linear(32, 1)\n",
        "        # Note: We will use BCEWithLogitsLoss which combines sigmoid and BCELoss for numerical stability,\n",
        "        # so the final activation here will *not* be sigmoid, it's implicitly handled by the loss.\n",
        "\n",
        "    def forward(self, user_id, candidate_item_id, historical_item_ids):\n",
        "        # Ensure inputs are 1D for embedding lookup\n",
        "        user_id = user_id.squeeze(-1) # (batch_size, 1) -> (batch_size,)\n",
        "        candidate_item_id = candidate_item_id.squeeze(-1) # (batch_size, 1) -> (batch_size,)\n",
        "\n",
        "        # Embeddings lookup\n",
        "        user_emb = self.user_embedding(user_id) # (batch_size, embedding_dim)\n",
        "        candidate_item_emb = self.item_embedding(candidate_item_id) # (batch_size, embedding_dim)\n",
        "        historical_item_embs = self.item_embedding(historical_item_ids) # (batch_size, history_length, embedding_dim)\n",
        "\n",
        "        # Pass through Attention Pooling Layer\n",
        "        attention_output = self.attention_pooling_layer(candidate_item_emb, historical_item_embs)\n",
        "\n",
        "        # Concatenate all features\n",
        "        concatenated_features = torch.cat([\n",
        "            user_emb,\n",
        "            candidate_item_emb,\n",
        "            attention_output\n",
        "        ], dim=-1)\n",
        "\n",
        "        # Pass through prediction MLP\n",
        "        mlp_output = self.mlp(concatenated_features)\n",
        "        # Final output (logits)\n",
        "        logits = self.output_layer(mlp_output)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Instantiate and move model to device\n",
        "din_model = DIN(\n",
        "    num_users=num_users,\n",
        "    num_items=num_items,\n",
        "    history_length=history_length,\n",
        "    embedding_dim=embedding_dim,\n",
        "    item_features_matrix=item_features_data_np\n",
        ").to(device)\n",
        "\n",
        "print(\"\\nDIN Model Summary:\")\n",
        "# A simple way to print model structure, similar to Keras summary\n",
        "print(din_model)\n",
        "# You might need to pass a dummy input to get details for each layer.\n",
        "# print(din_model(torch.zeros(2,1).long().to(device), torch.zeros(2,1).long().to(device), torch.zeros(2, history_length).long().to(device)))\n",
        "\n",
        "\n",
        "# --- 3. Prepare Data for Training (PyTorch DataLoader) ---\n",
        "dataset = TensorDataset(user_ids_data, candidate_item_ids_data, historical_item_ids_data, labels_data)\n",
        "\n",
        "# Split data into train and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# --- 4. Train the Model ---\n",
        "optimizer = torch.optim.Adam(din_model.parameters(), lr=0.001)\n",
        "criterion = nn.BCEWithLogitsLoss() # Combines Sigmoid and Binary Cross-Entropy for numerical stability\n",
        "\n",
        "num_epochs = 5\n",
        "print(f\"\\n--- Training the DIN Model for {num_epochs} epochs ---\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    din_model.train() # Set model to training mode\n",
        "    total_loss = 0\n",
        "    predictions_train = []\n",
        "    labels_train = []\n",
        "\n",
        "    for batch_idx, (user_ids, candidate_ids, historical_ids, labels) in enumerate(train_loader):\n",
        "        user_ids, candidate_ids, historical_ids, labels = \\\n",
        "            user_ids.to(device), candidate_ids.to(device), historical_ids.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "        outputs = din_model(user_ids, candidate_ids, historical_ids) # Forward pass\n",
        "        loss = criterion(outputs, labels) # Calculate loss\n",
        "        loss.backward() # Backward pass\n",
        "        optimizer.step() # Update weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Store predictions and labels for metrics\n",
        "        predictions_train.extend(outputs.sigmoid().detach().cpu().numpy().flatten())\n",
        "        labels_train.extend(labels.detach().cpu().numpy().flatten())\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    train_accuracy = accuracy_score(labels_train, np.round(predictions_train))\n",
        "    train_auc = roc_auc_score(labels_train, predictions_train)\n",
        "\n",
        "    # --- Validation ---\n",
        "    din_model.eval() # Set model to evaluation mode\n",
        "    val_total_loss = 0\n",
        "    predictions_val = []\n",
        "    labels_val = []\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculations\n",
        "        for user_ids, candidate_ids, historical_ids, labels in val_loader:\n",
        "            user_ids, candidate_ids, historical_ids, labels = \\\n",
        "                user_ids.to(device), candidate_ids.to(device), historical_ids.to(device), labels.to(device)\n",
        "\n",
        "            outputs = din_model(user_ids, candidate_ids, historical_ids)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_total_loss += loss.item()\n",
        "\n",
        "            predictions_val.extend(outputs.sigmoid().cpu().numpy().flatten())\n",
        "            labels_val.extend(labels.cpu().numpy().flatten())\n",
        "\n",
        "    avg_val_loss = val_total_loss / len(val_loader)\n",
        "    val_accuracy = accuracy_score(labels_val, np.round(predictions_val))\n",
        "    val_auc = roc_auc_score(labels_val, predictions_val)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Train AUC: {train_auc:.4f}\")\n",
        "    print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "print(\"\\nTraining complete.\")\n",
        "\n",
        "# --- 5. Make Predictions (Example) ---\n",
        "print(\"\\n--- Making Predictions (Example) ---\")\n",
        "\n",
        "din_model.eval() # Set model to evaluation mode\n",
        "\n",
        "# Select a few random samples for prediction\n",
        "num_predict_samples = 5\n",
        "random_indices = np.random.choice(len(user_ids_data), num_predict_samples, replace=False)\n",
        "\n",
        "sample_user_ids = user_ids_data[random_indices].to(device)\n",
        "sample_candidate_item_ids = candidate_item_ids_data[random_indices].to(device)\n",
        "sample_historical_item_ids = historical_item_ids_data[random_indices].to(device)\n",
        "sample_labels = labels_data[random_indices].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample_outputs = din_model(sample_user_ids, sample_candidate_item_ids, sample_historical_item_ids)\n",
        "    sample_predictions = sample_outputs.sigmoid().cpu().numpy().flatten() # Apply sigmoid to get probabilities\n",
        "\n",
        "print(\"\\nSample Predictions:\")\n",
        "for i in range(num_predict_samples):\n",
        "    print(f\"  Sample {i+1}:\")\n",
        "    print(f\"    User ID: {sample_user_ids[i].item()}\")\n",
        "    print(f\"    Candidate Item ID: {sample_candidate_item_ids[i].item()}\")\n",
        "    print(f\"    Historical Item IDs: {sample_historical_item_ids[i].cpu().numpy().tolist()}\")\n",
        "    print(f\"    True Label: {sample_labels[i].item()}\")\n",
        "    print(f\"    Predicted Probability: {sample_predictions[i]:.4f}\")\n",
        "    print(\"-\" * 30)\n",
        "\n"
      ],
      "metadata": {
        "id": "DXwHrD7bK1mA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c1da971-b11f-4f7c-d6e5-e4cabd2ac4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.6.0+cu124\n",
            "Using device: cpu\n",
            "Generated synthetic data: 50000 samples.\n",
            "  User IDs shape: (50000,)\n",
            "  Candidate Item IDs shape: (50000,)\n",
            "  Historical Item IDs shape: (50000, 10)\n",
            "  Labels shape: (50000,)\n",
            "  Item Features matrix shape: (501, 16)\n",
            "\n",
            "DIN Model Summary:\n",
            "DIN(\n",
            "  (user_embedding): Embedding(1001, 16)\n",
            "  (item_embedding): Embedding(501, 16)\n",
            "  (attention_pooling_layer): AttentionPoolingLayer(\n",
            "    (attention_mlp): Sequential(\n",
            "      (0): Linear(in_features=64, out_features=80, bias=True)\n",
            "      (1): Dice()\n",
            "      (2): Linear(in_features=80, out_features=40, bias=True)\n",
            "      (3): Dice()\n",
            "    )\n",
            "    (output_layer): Linear(in_features=40, out_features=1, bias=True)\n",
            "  )\n",
            "  (mlp): Sequential(\n",
            "    (0): Linear(in_features=48, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.3, inplace=False)\n",
            "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (7): ReLU()\n",
            "  )\n",
            "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "--- Training the DIN Model for 5 epochs ---\n",
            "Epoch 1/5:\n",
            "  Train Loss: 0.6935, Train Acc: 0.5016, Train AUC: 0.4966\n",
            "  Val Loss: 0.6933, Val Acc: 0.4949, Val AUC: 0.4915\n",
            "Epoch 2/5:\n",
            "  Train Loss: 0.6930, Train Acc: 0.5062, Train AUC: 0.5058\n",
            "  Val Loss: 0.6933, Val Acc: 0.4910, Val AUC: 0.4938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QZV-Cu4uw--B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}